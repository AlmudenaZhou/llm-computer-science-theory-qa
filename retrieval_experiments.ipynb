{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/all_qa.json\") as file:\n",
    "    intents = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "hashes = defaultdict(list)\n",
    "\n",
    "for doc in intents:\n",
    "    doc_id = doc['id']\n",
    "    hashes[doc_id].append(doc)\n",
    "\n",
    "print(len(hashes), len(intents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add intents to ElasticSearch Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.client_modules.embeddings.transformer import TransformerEmbeddingModel\n",
    "\n",
    "\n",
    "emb_model = TransformerEmbeddingModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_text_template = (\"\"\"Equivalent questions: \\\"\"\"{patterns}\\\"\"\"\n",
    "Equivalent answers:\\\"\"\"{responses}\\\"\"\"\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "for intent in tqdm(intents):\n",
    "    embedding_text = embedding_text_template.format(\n",
    "        patterns='\\n\\n'.join(intent[\"patterns\"]),\n",
    "        responses='\\n\\n\"'.join(intent[\"responses\"])\n",
    "    )\n",
    "    intent['text'] = embedding_text\n",
    "    intent['vector_field'] = emb_model.get_embeddings([embedding_text])[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tiktoken\n",
    "\n",
    "\n",
    "def get_text_embedding(emb_model, embedding_text):\n",
    "    embedding = emb_model.get_embeddings([embedding_text])[0]\n",
    "    if isinstance(embedding, np.ndarray):\n",
    "        embedding = embedding.tolist()\n",
    "    return embedding\n",
    "\n",
    "def get_combined_qa_embedding(emb_model, intent):\n",
    "    embedding_text_template = (\"\"\"Question: {patterns}\\nAnswer:{responses}\"\"\")\n",
    "\n",
    "    embedding_text = embedding_text_template.format(\n",
    "        patterns=intent[\"patterns\"][0],\n",
    "        responses=intent[\"responses\"][0]\n",
    "    )\n",
    "\n",
    "    embedding = get_text_embedding(emb_model, embedding_text)\n",
    "\n",
    "    full_text = (\"\"\"Questions:\\n- {'\\n- '.join(intent[\"patterns\"])}\\nAnswers:\\n- {'\\n- '.join(intent[\"responses\"]}\"\"\")\n",
    "\n",
    "    return full_text, embedding_text, embedding\n",
    "\n",
    "def get_questions_embedding(emb_model, intent):\n",
    "\n",
    "    full_text = '\\n- '.join(intent[\"patterns\"])\n",
    "    embedding_text = intent[\"patterns\"][0]\n",
    "    embedding = get_text_embedding(emb_model, embedding_text)\n",
    "    return full_text, embedding_text, embedding\n",
    "\n",
    "def get_answers_embedding(emb_model, intent):\n",
    "    full_text = '\\n- '.join(intent[\"responses\"])\n",
    "    embedding_text = intent[\"responses\"][0]\n",
    "    embedding = get_text_embedding(emb_model, embedding_text)\n",
    "    return full_text, embedding_text, embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.client_modules.embeddings.azure_openai import AzureOpenAIEmbeddingModel\n",
    "\n",
    "\n",
    "emb_model = AzureOpenAIEmbeddingModel()\n",
    "\n",
    "es_docs = []\n",
    "\n",
    "\n",
    "for intent in tqdm(intents[:10]):\n",
    "    es_doc = {}\n",
    "    questions_full, questions_text, questions_embedding = get_questions_embedding(emb_model, intent)\n",
    "    es_doc[\"questions\"] = questions_full\n",
    "    es_doc[\"questions_vector_text\"] = questions_text\n",
    "    es_doc[\"questions_vector\"] = questions_embedding\n",
    "\n",
    "    answers_full, answers_text, answers_embedding = get_answers_embedding(emb_model, intent)\n",
    "    es_doc[\"answers\"] = answers_full\n",
    "    es_doc[\"answers_vector_text\"] = answers_text\n",
    "    es_doc[\"answers_vector\"] = answers_embedding\n",
    "\n",
    "    comb_full, comb_text, comb_embedding = get_combined_qa_embedding(emb_model, intent)\n",
    "    es_doc[\"combined_qa\"] = comb_full\n",
    "    es_doc[\"combined_qa_vector_text\"] = comb_text\n",
    "    es_doc[\"combined_qa_vector\"] = comb_embedding\n",
    "\n",
    "    es_doc[\"id\"] = intent[\"id\"]\n",
    "    es_doc[\"document\"] = intent[\"document\"]\n",
    "\n",
    "    es_docs.append(es_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.client_modules.elastic_search.elastic_search_client import ElasticSearchClient\n",
    "\n",
    "\n",
    "es_client = ElasticSearchClient(port=9200)\n",
    "\n",
    "index_name = \"cs-theory\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mappings and Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You do not need to specify in ElasticSearch a different type to indicate that they will hold arrays.\n",
    "https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-types.html#types-array-handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = 1536 # len(es_docs[0][\"combined_qa_vector\"])\n",
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"id\": {\"type\": \"text\"},\n",
    "            \"document\": {\"type\": \"text\"},\n",
    "            \"questions\": {\"type\": \"text\"},\n",
    "            \"answers\": {\"type\": \"text\"},\n",
    "            \"combined_qa\": {\"type\": \"text\"},\n",
    "            \"questions_vector_text\": {\"type\": \"text\"},\n",
    "            \"answers_vector_text\": {\"type\": \"text\"},\n",
    "            \"combined_qa_vector_text\": {\"type\": \"text\"},\n",
    "            \"combined_qa_vector\": {\"type\": \"dense_vector\", \"dims\": dimension},\n",
    "            \"questions_vector\": {\"type\": \"dense_vector\", \"dims\": dimension},\n",
    "            \"answers_vector\": {\"type\": \"dense_vector\", \"dims\": dimension},\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "es_client.create_index(index_name=index_name, index_settings=index_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add documents into index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_client.index_documents(index_name=index_name, documents=es_docs[0:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ElasticSearch Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.client_modules.embeddings.transformer import TransformerEmbeddingModel "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic search connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.client_modules.elastic_search.elastic_search_client import ElasticSearchClient\n",
    "\n",
    "\n",
    "es_client = ElasticSearchClient(port=9200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Tell me what is a syntax error\"\n",
    "\n",
    "emb_model = TransformerEmbeddingModel()\n",
    "emb_model = AzureOpenAIEmbeddingModel()\n",
    "vector_search_term = emb_model.get_embeddings([question])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_query1 = {\n",
    "  \"query\": {\n",
    "    \"script_score\": {\n",
    "      \"query\": {\n",
    "        \"match_all\": {}\n",
    "      },\n",
    "      \"script\": {\n",
    "        \"source\": \"dotProduct(params.query_vector, 'combined_qa_vector') + 1.0\",\n",
    "        \"params\": {\n",
    "          \"query_vector\": vector_search_term\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "search_query2 = {\n",
    "  \"query\": {\n",
    "    \"script_score\": {\n",
    "      \"query\": { \"match_all\": {} },\n",
    "      \"script\": {\n",
    "        \"source\": \"\"\"\n",
    "          0.5 * dotProduct(params.query_vector, 'combined_qa_vector') +\n",
    "          0.25 * dotProduct(params.query_vector, 'answers_vector') +\n",
    "          0.25 * dotProduct(params.query_vector, 'questions_vector')\n",
    "        \"\"\",\n",
    "        \"params\": {\n",
    "          \"query_vector\": vector_search_term\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "search_query3 = {\n",
    "  \"query\": {\n",
    "    \"script_score\": {\n",
    "      \"query\": { \"match_all\": {} },\n",
    "      \"script\": {\n",
    "        \"source\": \"\"\"\n",
    "          (dotProduct(params.query_vector, 'combined_qa_vector') +\n",
    "           dotProduct(params.query_vector, 'answers_vector') +\n",
    "           dotProduct(params.query_vector, 'questions_vector')) / 3\n",
    "        \"\"\",\n",
    "        \"params\": {\n",
    "          \"query_vector\": vector_search_term\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "\n",
    "search_query4 = {\n",
    "  \"query\": {\n",
    "    \"script_score\": {\n",
    "      \"query\": { \"match_all\": {} },\n",
    "      \"script\": {\n",
    "        \"source\": \"\"\"\n",
    "          Math.max(\n",
    "            dotProduct(params.query_vector, 'combined_qa_vector'),\n",
    "            dotProduct(params.query_vector, 'answers_vector'),\n",
    "            dotProduct(params.query_vector, 'questions_vector')\n",
    "          )\n",
    "        \"\"\",\n",
    "        \"params\": {\n",
    "          \"query_vector\": vector_search_term\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = es_client.search(index_name=index_name, search_query=search_query1)\n",
    "res[\"hits\"][\"hits\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs-qa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
